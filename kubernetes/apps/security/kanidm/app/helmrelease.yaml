---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: &app kanidm
  namespace: security
spec:
  interval: 10m
  chart:
    spec:
      chart: app-template
      version: 2.6.0
      sourceRef:
        name: bjw-s
        kind: HelmRepository
        namespace: flux-system
  values:
    defaultPodOptions:
      nodeSelector:
        openebs.io/storage: "true"
    automountServiceAccountToken: false
    controller:
      type: statefulset
    image:
      repository: docker.io/kanidm/server
      tag: latest@sha256:b3986fde81ae6572883fed4a1f0827fa1acb3b27241b06b61b5efce9cf265f1d
    env:
      TZ: "${TZ}"
    service:
      main:
        enabled: true
        type: LoadBalancer
        externalTrafficPolicy: Local
        annotations:
          coredns.io/hostname: "idm.${SECRET_DOMAIN}"
          "io.cilium/lb-ipam-ips": "10.17.8.7"
        externalIPs:
          - "10.17.8.7"
        ports:
          http:
            enabled: true
            port: 443
            targetPort: 8443
            protocol: HTTPS
          ldap-tcp:
            enabled: true
            port: 636
            targetPort: 3636
            protocol: TCP
          ldap-udp:
            enabled: true
            port: 636
            targetPort: 3636
            protocol: UDP
    ingress:
      main:
        enabled: true
        primary: true
        ingressClassName: internal
        annotations:
          nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
          # https://github.com/kubernetes/ingress-nginx/issues/6728
          nginx.ingress.kubernetes.io/server-snippet: |
            proxy_ssl_name idm.${SECRET_DOMAIN};
            proxy_ssl_server_name on;
            large_client_header_buffers 4 8k;
            client_header_buffer_size 8k;
          # without header buffer size, will get following errors due to hardening ingress-nginx number of header buffers to 2 and header buffer size to 1k:
          # HTTP1.1 /v1/auth/valid: 400 Request Header Or Cookie Too Large
          # HTTP2 /v1/auth/valid: HTTP/2 stream was not closed cleanly before end of the underlying stream
        hosts:
          - host: &host "idm.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
        tls:
          - hosts:
              - *host
#     dnsConfig:
#       options:
#         - name: ndots
#           value: "1"
    podSecurityContext:
      runAsUser: &uid 1500
      runAsGroup: *uid
      fsGroup: *uid
      fsGroupChangePolicy: Always
    volumeClaimTemplates:
      - name: data
        mountPath: /data
        accessMode: ReadWriteOnce
        size: 500Mi
        storageClass: openebs-hostpath
      - name: backup
        mountPath: /backup
        accessMode: ReadWriteOnce
        size: 500Mi
        storageClass: openebs-hostpath
    persistence:
      config:
        enabled: true
        type: configMap
        name: kanidm-config
        subPath: server.toml
        mountPath: /data/server.toml
        readOnly: true
      tls-fullchain:
        enabled: true
        type: secret
        name: kanidm-tls
        subPath: tls.crt
        mountPath: /tls/fullchain.pem
        readOnly: true
      tls-privkey:
        enabled: true
        type: secret
        name: kanidm-tls
        subPath: tls.key
        mountPath: /tls/privkey.pem
        readOnly: true
    configMaps:
      config:
        enabled: true
        data:
          server.toml: |-
            domain = "idm.${SECRET_DOMAIN}"
            origin = "https://idm.${SECRET_DOMAIN}"
            tls_chain = "/tls/fullchain.pem"
            tls_key = "/tls/privkey.pem"
            role = "WriteReplica"
            log_level = "verbose"
            bindaddress = "[::]:8443"
            ldapbindaddress = "[::]:3636"
            trust_x_forward_for = true
            db_path = "/data/kanidm.db"
            db_fs_type = "other"
            [online_backup]
            path = "/backup/"
            schedule = "0 0 22 * * * *"
            versions = 7
    resources:
      requests:
        cpu: 10m
        memory: 128Mi
      limits:
        memory: 6000Mi
    initContainers:
      01-init-kanidm-admin-password:
        command:
        - /bin/sh
        - -c
        - '[ -s /data/kanidm.db ] || /sbin/kanidmd recover_account -c /data/server.toml admin'
        image: docker.io/kanidm/server:latest@sha256:b3986fde81ae6572883fed4a1f0827fa1acb3b27241b06b61b5efce9cf265f1d
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - mountPath: /data
          name: data
        - mountPath: /config
          name: config
